{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN_Cifar.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOQTuKcPGtK5uTlOZl8co8S",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/asetya/BigData/blob/master/CNN_Cifar.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bn0HK-n1RZQv"
      },
      "source": [
        "# CNN with CIFAR DATASET "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YEaGkT06RkuV"
      },
      "source": [
        "sumber : https://www.analyticsvidhya.com/blog/2020/02/learn-image-classification-cnn-convolutional-neural-networks-3-datasets/\n",
        "\n",
        "CIFAR-10 adalah dataset citra  yang terdiri dari 60.000 gambar ukuran 32x32 \n",
        "\n",
        "terdiri dari 50.000 training dan 10.000 testing \n",
        "\n",
        "Kita akan mencoba arsitektur CNN sederhana untuk mengelompokan (klasifikasi) gambar menjadi 10 kelas "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-qGtNBstRjVL",
        "outputId": "d22d1fe4-afee-46b3-817d-18ff8c6fd611"
      },
      "source": [
        "from keras.datasets import cifar10\n",
        "# loading the dataset \n",
        "(X_train, y_train), (X_test, y_test) = cifar10.load_data()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 6s 0us/step\n",
            "170508288/170498071 [==============================] - 6s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dOn1GFquSbzM"
      },
      "source": [
        "Import Library "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nzoaM2ueSgZD"
      },
      "source": [
        "# keras imports for the dataset and building our neural network\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Conv2D, MaxPool2D, Flatten\n",
        "from keras.utils import np_utils\n",
        "\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gcr_-B3cSoZb"
      },
      "source": [
        "Menyiapkan dataset "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6_IHVx87SsC7",
        "outputId": "75c4ae8b-18b2-4f40-de30-0e8e0a43227b"
      },
      "source": [
        "# loading the dataset\n",
        "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
        "\n",
        "# # building the input vector from the 32x32 pixels\n",
        "X_train = X_train.reshape(X_train.shape[0], 32, 32, 3)\n",
        "X_test = X_test.reshape(X_test.shape[0], 32, 32, 3)\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "\n",
        "# normalizing the data to help with the training\n",
        "X_train /= 255\n",
        "X_test /= 255\n",
        "\n",
        "# one-hot encoding using keras' numpy-related utilities\n",
        "n_classes = 10\n",
        "print(\"Shape before one-hot encoding: \", y_train.shape)\n",
        "Y_train = np_utils.to_categorical(y_train, n_classes)\n",
        "Y_test = np_utils.to_categorical(y_test, n_classes)\n",
        "print(\"Shape after one-hot encoding: \", Y_train.shape)\n",
        "\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape before one-hot encoding:  (50000, 1)\n",
            "Shape after one-hot encoding:  (50000, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FvophN8_SxkL"
      },
      "source": [
        "Membuat Model "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HH7ulOr_Sw3q"
      },
      "source": [
        "# building a linear stack of layers with the sequential model\n",
        "model = Sequential()\n",
        "\n",
        "# convolutional layer\n",
        "model.add(Conv2D(50, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu', input_shape=(32, 32, 3)))\n",
        "\n",
        "# convolutional layer\n",
        "model.add(Conv2D(75, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu'))\n",
        "model.add(MaxPool2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(125, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu'))\n",
        "model.add(MaxPool2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "# flatten output of conv\n",
        "model.add(Flatten())\n",
        "\n",
        "# hidden layer\n",
        "model.add(Dense(500, activation='relu'))\n",
        "model.add(Dropout(0.4))\n",
        "model.add(Dense(250, activation='relu'))\n",
        "model.add(Dropout(0.3))\n",
        "# output layer\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "# compiling the sequential model\n",
        "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')\n",
        "\n",
        "#menampilkan model \n",
        "print(model.summary())\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7OR-H1KXS72j"
      },
      "source": [
        "Melakukan Training dan Validasi"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qbrSV38oS_u7",
        "outputId": "bd20e97b-7f67-4a64-c81c-6dc304754660"
      },
      "source": [
        "# training the model for 10 epochs\n",
        "model.fit(X_train, Y_train, batch_size=128, epochs=10, validation_data=(X_test, Y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "391/391 [==============================] - 376s 927ms/step - loss: 1.8615 - accuracy: 0.3051 - val_loss: 1.1985 - val_accuracy: 0.5792\n",
            "Epoch 2/10\n",
            "  8/391 [..............................] - ETA: 5:40 - loss: 1.2924 - accuracy: 0.5530"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}